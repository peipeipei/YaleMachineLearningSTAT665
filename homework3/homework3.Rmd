---
title: "Homework 3"
author: "Pei Tao"
date: "6/19/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
train <- read.csv("digits_train.csv", as.is = TRUE)
valid <- read.csv("digits_valid.csv", as.is = TRUE)
test <- read.csv("digits_test.csv", as.is = TRUE)
```

## Part 1 

```{r}
plotDigit <- function(k, dat) {
  p <- matrix(as.numeric(dat[k,1:256]),16,16)
  image(x=1:16, y=1:16, p[,16:1], xlab="", ylab="", main=paste("Row: ", k, " | Digit: ", dat[k,257]))
  return()
}
```

I imagine that 1’s and 7’s will be hard to distinguish. Perhaps due to the way that these pixel data were normalized from the input device, there seems to be an unusually long left-stroke on the 1’s.

```{r}
par(mfrow=c(3,4))
set.seed(665)
ones <- train[train$digit == 1,]
sevens <- train[train$digit == 7,]
v <- sapply(sample(1:nrow(ones), 6), plotDigit, dat=ones)
v <- sapply(sample(1:nrow(sevens), 6), plotDigit, dat=sevens)
```

## Part 2

### K-Nearest Neighbors

Train a k-nearest neighbor and a linear discriminant analysis classifier using your training set. Of course, you may need to find a good value of k, and the validation set could be helpful for that part.

```{r}
library(FNN)

kvals <- 1:40
error <- rep(NA, length(kvals))
for (i in 1:length(kvals)) {
  k <- kvals[i]
  res <- knn(train[,-257], valid[,-257], train[,257], k=k)
  error[i] <- mean(res != valid[,257])
}

plot(error ~ kvals, type="l", main="Validation Error Rates by k", xlab="k")
```

```{r}
kvals[which.min(error)]
error[kvals[which.min(error)]]
```

Best k-nearest neighbors approach appears to use k = 1 neighbor.
The best error rate achieved is 11.3%.

### Logistic Regression

Logistic regression should not be used here because there are far too many columns in the dataset.

### LDA

```{r}
library(MASS)

m3 <- lda(digit ~., data=train)
p3 <- predict(m3, newdata=valid)$class
table(p3, valid$digit)
```

```{r}
mean(p3 != valid$digit)
```

The full LDA model gives us a validation error rate of 19.8%.

```{r}
res <- knn(train[,-257], valid[,-257], train[,257], k=1)
knn_confusion <- table(fitted=res, actual=valid$digit)
lda_confusion <- table(fitted=p3, actual=valid$digit)
knn_confusion
```

```{r}
lda_confusion
```


```{r}
(colSums(knn_confusion) - diag(knn_confusion))/colSums(knn_confusion)
```

Percentage misclassified by digit by KNN approach

```{r}
(colSums(lda_confusion) - diag(lda_confusion))/colSums(lda_confusion)
```

Percentage misclassified by digit by LDA approach

```{r}
knn_pred <- knn(rbind(train[,-257], valid[,-257]),
test[-257], c(train[,257], valid[,257]), k=6)
lda_model <- lda(digit ~., data=rbind(train, valid))
lda_pred <- predict(lda_model, newdata=test)$class

write.csv(data.frame(knn_pred = knn_pred, lda_pred = lda_pred), "HW3_netid.csv", row.names = FALSE)
```

# Part 3

We will explore the use of multinomial logistic regression with a dimension-reduction pre-processing step, achieved using linear discriminant analysis.

```{r}
m1 <- lda(digit ~ ., data=train)
trainlds <- as.data.frame(predict(m1)$x)
trainlds$digit <- train$digit
validlds <- as.data.frame(predict(m1, newdata=valid)$x)
validlds$digit <- valid$digit
```

```{r}
library(nnet)
errs <- rep(NA, 9)
for (k in 1:9) {
f <- paste("digit ~", paste(paste("LD", 1:k, sep=""), collapse=" + "))
m2 <- multinom(as.formula(f), data=trainlds, trace=FALSE)
preds <- predict(m2, newdata=validlds)
errs[k] <- mean(preds != valid$digit)
}
plot(1:9, errs, main="Validation Error for Different Logit Models",
xlab="# Linear Discriminants Used", ylab="Misclassification Error Rate")
```







